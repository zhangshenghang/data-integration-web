"use strict";(self.webpackChunkseatunnel_website=self.webpackChunkseatunnel_website||[]).push([[30075],{15680:(e,n,t)=>{t.d(n,{xA:()=>p,yg:()=>g});var a=t(96540);function r(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function o(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function l(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?o(Object(t),!0).forEach((function(n){r(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function i(e,n){if(null==e)return{};var t,a,r=function(e,n){if(null==e)return{};var t,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)t=o[a],n.indexOf(t)>=0||(r[t]=e[t]);return r}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)t=o[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var s=a.createContext({}),c=function(e){var n=a.useContext(s),t=n;return e&&(t="function"==typeof e?e(n):l(l({},n),e)),t},p=function(e){var n=c(e.components);return a.createElement(s.Provider,{value:n},e.children)},u="mdxType",f={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},d=a.forwardRef((function(e,n){var t=e.components,r=e.mdxType,o=e.originalType,s=e.parentName,p=i(e,["components","mdxType","originalType","parentName"]),u=c(t),d=r,g=u["".concat(s,".").concat(d)]||u[d]||f[d]||o;return t?a.createElement(g,l(l({ref:n},p),{},{components:t})):a.createElement(g,l({ref:n},p))}));function g(e,n){var t=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var o=t.length,l=new Array(o);l[0]=d;var i={};for(var s in n)hasOwnProperty.call(n,s)&&(i[s]=n[s]);i.originalType=e,i[u]="string"==typeof e?e:r,l[1]=i;for(var c=2;c<o;c++)l[c]=t[c];return a.createElement.apply(null,l)}return a.createElement.apply(null,t)}d.displayName="MDXCreateElement"},22008:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>s,contentTitle:()=>l,default:()=>f,frontMatter:()=>o,metadata:()=>i,toc:()=>c});var a=t(58168),r=(t(96540),t(15680));const o={},l="Flink SQL Kafka Connector",i={unversionedId:"connector/flink-sql/Kafka",id:"version-2.3.0-beta/connector/flink-sql/Kafka",title:"Flink SQL Kafka Connector",description:"Kafka connector based by flink sql",source:"@site/versioned_docs/version-2.3.0-beta/connector/flink-sql/Kafka.md",sourceDirName:"connector/flink-sql",slug:"/connector/flink-sql/Kafka",permalink:"/zh-CN/docs/2.3.0-beta/connector/flink-sql/Kafka",draft:!1,editUrl:"https://github.com/apache/seatunnel-website/edit/main/versioned_docs/version-2.3.0-beta/connector/flink-sql/Kafka.md",tags:[],version:"2.3.0-beta",frontMatter:{},sidebar:"docs",previous:{title:"Flink SQL JDBC Connector",permalink:"/zh-CN/docs/2.3.0-beta/connector/flink-sql/Jdbc"},next:{title:"How to use flink sql module",permalink:"/zh-CN/docs/2.3.0-beta/connector/flink-sql/usage"}},s={},c=[{value:"Description",id:"description",level:2},{value:"Usage",id:"usage",level:2},{value:"1. kafka prepare",id:"1-kafka-prepare",level:3},{value:"2. prepare seatunnel configuration",id:"2-prepare-seatunnel-configuration",level:3},{value:"3. start flink local cluster",id:"3-start-flink-local-cluster",level:3},{value:"4. start Flink SQL job",id:"4-start-flink-sql-job",level:3},{value:"5. verify result",id:"5-verify-result",level:3}],p={toc:c},u="wrapper";function f(e){let{components:n,...t}=e;return(0,r.yg)(u,(0,a.A)({},p,t,{components:n,mdxType:"MDXLayout"}),(0,r.yg)("h1",{id:"flink-sql-kafka-connector"},"Flink SQL Kafka Connector"),(0,r.yg)("blockquote",null,(0,r.yg)("p",{parentName:"blockquote"},"Kafka connector based by flink sql")),(0,r.yg)("h2",{id:"description"},"Description"),(0,r.yg)("p",null,"With kafka connector, we can read data from kafka and write data to kafka using Flink SQL. Refer to the ",(0,r.yg)("a",{parentName:"p",href:"https://nightlies.apache.org/flink/flink-docs-release-1.13/docs/connectors/table/kafka/"},"Kafka connector")," for more details."),(0,r.yg)("h2",{id:"usage"},"Usage"),(0,r.yg)("p",null,"Let us have a brief example to show how to use the connector from end to end."),(0,r.yg)("h3",{id:"1-kafka-prepare"},"1. kafka prepare"),(0,r.yg)("p",null,"Please refer to the ",(0,r.yg)("a",{parentName:"p",href:"https://kafka.apache.org/quickstart"},"Kafka QuickStart")," to prepare kafka environment and produce data like following:"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-bash"},"$ bin/kafka-console-producer.sh --topic <topic-name> --bootstrap-server localhost:9092\n")),(0,r.yg)("p",null,"After executing the command, we will come to the interactive mode. Print the following message to send data to kafka."),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-bash"},'{"id":1,"name":"abc"}\n>{"id":2,"name":"def"}\n>{"id":3,"name":"dfs"}\n>{"id":4,"name":"eret"}\n>{"id":5,"name":"yui"}\n')),(0,r.yg)("h3",{id:"2-prepare-seatunnel-configuration"},"2. prepare seatunnel configuration"),(0,r.yg)("p",null,"Here is a simple example of seatunnel configuration."),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-sql"},"SET table.dml-sync = true;\n\nCREATE TABLE events (\n    id INT,\n    name STRING\n) WITH (\n    'connector' = 'kafka',\n    'topic'='<topic-name>',\n    'properties.bootstrap.servers' = 'localhost:9092',\n    'properties.group.id' = 'testGroup',\n    'scan.startup.mode' = 'earliest-offset',\n    'format' = 'json'\n);\n\nCREATE TABLE print_table (\n    id INT,\n    name STRING\n) WITH (\n    'connector' = 'print',\n    'sink.parallelism' = '1'\n);\n\nINSERT INTO print_table SELECT * FROM events;\n")),(0,r.yg)("h3",{id:"3-start-flink-local-cluster"},"3. start flink local cluster"),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-bash"},"$ ${FLINK_HOME}/bin/start-cluster.sh\n")),(0,r.yg)("h3",{id:"4-start-flink-sql-job"},"4. start Flink SQL job"),(0,r.yg)("p",null,"Execute the following command in seatunnel home path to start the Flink SQL job."),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-bash"},"$ bin/start-seatunnel-sql.sh -c config/kafka.sql.conf\n")),(0,r.yg)("h3",{id:"5-verify-result"},"5. verify result"),(0,r.yg)("p",null,"After the job submitted, we can see the data printing by connector 'print' in taskmanager's log ."),(0,r.yg)("pre",null,(0,r.yg)("code",{parentName:"pre",className:"language-text"},"+I[1, abc]\n+I[2, def]\n+I[3, dfs]\n+I[4, eret]\n+I[5, yui]\n")))}f.isMDXComponent=!0}}]);