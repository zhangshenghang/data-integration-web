"use strict";(self.webpackChunkseatunnel_website=self.webpackChunkseatunnel_website||[]).push([[49971],{15680:(e,n,t)=>{t.d(n,{xA:()=>s,yg:()=>m});var r=t(96540);function a(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function o(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);n&&(r=r.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,r)}return t}function i(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?o(Object(t),!0).forEach((function(n){a(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function l(e,n){if(null==e)return{};var t,r,a=function(e,n){if(null==e)return{};var t,r,a={},o=Object.keys(e);for(r=0;r<o.length;r++)t=o[r],n.indexOf(t)>=0||(a[t]=e[t]);return a}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)t=o[r],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(a[t]=e[t])}return a}var u=r.createContext({}),p=function(e){var n=r.useContext(u),t=n;return e&&(t="function"==typeof e?e(n):i(i({},n),e)),t},s=function(e){var n=p(e.components);return r.createElement(u.Provider,{value:n},e.children)},c="mdxType",d={inlineCode:"code",wrapper:function(e){var n=e.children;return r.createElement(r.Fragment,{},n)}},g=r.forwardRef((function(e,n){var t=e.components,a=e.mdxType,o=e.originalType,u=e.parentName,s=l(e,["components","mdxType","originalType","parentName"]),c=p(t),g=a,m=c["".concat(u,".").concat(g)]||c[g]||d[g]||o;return t?r.createElement(m,i(i({ref:n},s),{},{components:t})):r.createElement(m,i({ref:n},s))}));function m(e,n){var t=arguments,a=n&&n.mdxType;if("string"==typeof e||a){var o=t.length,i=new Array(o);i[0]=g;var l={};for(var u in n)hasOwnProperty.call(n,u)&&(l[u]=n[u]);l.originalType=e,l[c]="string"==typeof e?e:a,i[1]=l;for(var p=2;p<o;p++)i[p]=t[p];return r.createElement.apply(null,i)}return r.createElement.apply(null,t)}g.displayName="MDXCreateElement"},75798:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>u,contentTitle:()=>i,default:()=>d,frontMatter:()=>o,metadata:()=>l,toc:()=>p});var r=t(58168),a=(t(96540),t(15680));const o={},i="Contribute Spark Plugins",l={unversionedId:"contribution/contribute-plugin",id:"version-2.1.1/contribution/contribute-plugin",title:"Contribute Spark Plugins",description:"There are two parent modules for Spark plugins:",source:"@site/versioned_docs/version-2.1.1/contribution/contribute-plugin.md",sourceDirName:"contribution",slug:"/contribution/contribute-plugin",permalink:"/docs/2.1.1/contribution/contribute-plugin",draft:!1,editUrl:"https://github.com/apache/seatunnel-website/edit/main/versioned_docs/version-2.1.1/contribution/contribute-plugin.md",tags:[],version:"2.1.1",frontMatter:{}},u={},p=[{value:"Create plugin module",id:"create-plugin-module",level:2},{value:"Add plugin implementation",id:"add-plugin-implementation",level:2},{value:"Add plugin to the distribution",id:"add-plugin-to-the-distribution",level:2}],s={toc:p},c="wrapper";function d(e){let{components:n,...t}=e;return(0,a.yg)(c,(0,r.A)({},s,t,{components:n,mdxType:"MDXLayout"}),(0,a.yg)("h1",{id:"contribute-spark-plugins"},"Contribute Spark Plugins"),(0,a.yg)("p",null,"There are two parent modules for Spark plugins:"),(0,a.yg)("ol",null,(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("a",{parentName:"li",href:"https://github.com/apache/incubator-seatunnel/tree/dev/seatunnel-connectors/seatunnel-connectors-spark"},"seatunnel-connectors-spark")),(0,a.yg)("li",{parentName:"ol"},(0,a.yg)("a",{parentName:"li",href:"https://github.com/apache/incubator-seatunnel/tree/dev/seatunnel-transforms/seatunnel-transforms-spark"},"seatunnel-transforms-spark"))),(0,a.yg)("p",null,"Once you want to contribute a new plugin, you need to:"),(0,a.yg)("h2",{id:"create-plugin-module"},"Create plugin module"),(0,a.yg)("p",null,"Create your plugin module under the corresponding parent plugin module.\nFor example, if you want to add a new Spark connector plugin, you need to create a new module under the ",(0,a.yg)("inlineCode",{parentName:"p"},"seatunnel-connectors-spark")," module."),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-java"},'<project xmlns="http://maven.apache.org/POM/4.0.0"\n         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"\n         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">\n    <parent>\n        <groupId>org.apache.seatunnel</groupId>\n        <artifactId>seatunnel-connectors-spark</artifactId>\n        <version>${revision}</version>\n    </parent>\n    <modelVersion>4.0.0</modelVersion>\n\n    <artifactId>seatunnel-connector-spark-hello</artifactId>\n\n    <dependencies>\n        <dependency>\n            <groupId>org.apache.seatunnel</groupId>\n            <artifactId>seatunnel-api-spark</artifactId>\n            <version>${project.version}</version>\n        </dependency>\n    </dependencies>\n</project>\n')),(0,a.yg)("h2",{id:"add-plugin-implementation"},"Add plugin implementation"),(0,a.yg)("p",null,"You need to implement the ",(0,a.yg)("inlineCode",{parentName:"p"},"Connector")," service provider interface. e.g. ",(0,a.yg)("inlineCode",{parentName:"p"},"BaseSource"),"/",(0,a.yg)("inlineCode",{parentName:"p"},"BaseSink"),"."),(0,a.yg)("p",null,"Conveniently, there are some abstract class can help you easy to create your plugin. If you want to create a source connector,\nyou can implement with ",(0,a.yg)("inlineCode",{parentName:"p"},"SparkBatchSource"),"/",(0,a.yg)("inlineCode",{parentName:"p"},"SparkStreamingSource"),". If you want to create a sink connector, you can implement with ",(0,a.yg)("inlineCode",{parentName:"p"},"SparkBatchSink"),"/",(0,a.yg)("inlineCode",{parentName:"p"},"SparkStreamingSink"),"."),(0,a.yg)("p",null,"The methods defined in ",(0,a.yg)("inlineCode",{parentName:"p"},"SparkBatchSource")," are some lifecycle methods. will be executed by SeaTunnel engine.\nThe execution order of the lifecycle methods is: ",(0,a.yg)("inlineCode",{parentName:"p"},"checkConfig")," -> ",(0,a.yg)("inlineCode",{parentName:"p"},"prepare")," -> ",(0,a.yg)("inlineCode",{parentName:"p"},"getData")," -> ",(0,a.yg)("inlineCode",{parentName:"p"},"close"),"."),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-java"},'import java.util.Date;\n\npublic class Hello extends SparkBatchSource {\n    @Override\n    public Dataset<Row> getData(SparkEnvironment env) {\n        // do your logic here to generate data\n        Dataset<Row> dataset = null;\n        return dataset;\n    }\n\n    @Override\n    public CheckResult checkConfig() {\n        return super.checkConfig();\n    }\n\n    @Override\n    public void prepare(SparkEnvironment env) {\n        super.prepare(env);\n    }\n\n    @Override\n    public void close() throws Exception {\n        super.close();\n    }\n\n    @Override\n    public String getPluginName() {\n        return "hello";\n    }\n}\n')),(0,a.yg)("p",null,"The ",(0,a.yg)("inlineCode",{parentName:"p"},"getPluginName")," method is used to identify the plugin name."),(0,a.yg)("p",null,"After you finish your implementation, you need to add a service provider to the ",(0,a.yg)("inlineCode",{parentName:"p"},"META-INF/services")," file.\nThe file name should be ",(0,a.yg)("inlineCode",{parentName:"p"},"org.apache.seatunnel.spark.BaseSparkSource")," or ",(0,a.yg)("inlineCode",{parentName:"p"},"org.apache.seatunnel.spark.BaseSparkSink"),", dependents on the plugin type.\nThe content of the file should be the fully qualified class name of your implementation."),(0,a.yg)("h2",{id:"add-plugin-to-the-distribution"},"Add plugin to the distribution"),(0,a.yg)("p",null,"You need to add your plugin to the ",(0,a.yg)("inlineCode",{parentName:"p"},"seatunnel-core-spark")," module, then the plugin will in distribution."),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-java"},"<dependency>\n    <groupId>org.apache.seatunnel</groupId>\n    <artifactId>seatunnel-connector-spark-hello</artifactId>\n    <version>${project.version}</version>\n</dependency>\n")),(0,a.yg)("h1",{id:"contribute-flink-plugins"},"Contribute Flink Plugins"),(0,a.yg)("p",null,"The steps to contribute a Flink plugin is similar to the steps to contribute a Spark plugin.\nDifferent from Spark, you need to add your plugin in Flink plugin modules."),(0,a.yg)("h1",{id:"add-e2e-tests-for-your-plugin"},"Add e2e tests for your plugin"),(0,a.yg)("p",null,"Once you add a new plugin, it is recommended to add e2e tests for it. We have a ",(0,a.yg)("inlineCode",{parentName:"p"},"seatunnel-e2e")," module to help you to do this."),(0,a.yg)("p",null,"For example, if you want to add an e2e test for your flink connector, you can create a new test in ",(0,a.yg)("inlineCode",{parentName:"p"},"seatunnel-flink-e2e")," module.\nAnd extend the FlinkContainer class in the test."),(0,a.yg)("pre",null,(0,a.yg)("code",{parentName:"pre",className:"language-java"},'public class HellpSourceIT extends FlinkContainer {\n\n    @Test\n    public void testHellpSource() throws IOException, InterruptedException {\n        Container.ExecResult execResult = executeSeaTunnelFlinkJob("/hello/hellosource.conf");\n        Assert.assertEquals(0, execResult.getExitCode());\n        // do some other assertion here\n    }\n\n')),(0,a.yg)("p",null,"Once your class implements the ",(0,a.yg)("inlineCode",{parentName:"p"},"FlinkContainer")," interface, it will auto create a Flink cluster in Docker, and you just need to\nexecute the ",(0,a.yg)("inlineCode",{parentName:"p"},"executeSeaTunnelFlinkJob")," method with your SeaTunnel configuration file, it will submit the SeaTunnel job."),(0,a.yg)("p",null,"In most times, you need to start a third-part datasource in your test, for example, if you add a clickhouse connectors, you may need to\nstart a Clickhouse database in your test. You can use ",(0,a.yg)("inlineCode",{parentName:"p"},"GenericContainer")," to start a container."),(0,a.yg)("p",null,"It should be noted that your e2e test class should be named ending with ",(0,a.yg)("inlineCode",{parentName:"p"},"IT"),". By default, we will not execute the test if the class name ending with ",(0,a.yg)("inlineCode",{parentName:"p"},"IT"),".\nYou can add ",(0,a.yg)("inlineCode",{parentName:"p"},"-DskipIT=false")," to execute the e2e test, it will rely on a Docker environment."))}d.isMDXComponent=!0}}]);